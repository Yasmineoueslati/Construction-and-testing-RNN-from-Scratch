{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oGt-Q3L914hV"
   },
   "source": [
    "## RNN training from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AWDy5dp513Zy",
    "outputId": "665ce9d5-8b32-4c1d-cc28-a3d53244add2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JizIY1QaLB8W"
   },
   "source": [
    "## 1) Time series generation\n",
    "\n",
    "In this first step, you will create a synthetic dataset of discrete-time trajectories based on a very simple model.\n",
    "\n",
    "It writes down as follows\n",
    "$$\n",
    "\\forall t \\in \\mathbb{N}, \\ x^k (t)= 0.5  \\sin \\left(100 f_1 (t-\\varphi_1) \\right) + 0.2 * \\sin \\left( 400 f_2 (t - \\varphi_2) \\right) + 0.1 c \\ \\mbox{with} \\ f_1,f_2, \\varphi_1, \\varphi_2 \\sim \\mathcal{U} (\\left[0,1 \\right]) \\ \\mbox{and} \\ c \\sim \\mathcal{U} ([-0.5,0.5 ]).\n",
    "$$\n",
    "\n",
    "\n",
    "Generation of a set of 1000 independant realizations $(x^k(t))$ of the model above; each with $50+1$ time steps. \n",
    "\n",
    "This will be referred to as dataset $\\mathbf{D}$ in the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9iCCNMxs3gGw"
   },
   "outputs": [],
   "source": [
    "#def generate_time_series(batch_size, n_steps, n_dim):\n",
    "#  f1,f2,ph1, ph2 = np.random.rand(4, batch_size, n_dim)\n",
    "#  time=np.linspace(0,1, n_steps)\n",
    "#  series = np.zeros((n_sample,n_steps+1,n_dim))\n",
    "#  series  = 0.5*np.sin((time-ph1)*f1*100)\n",
    "#  series += 0.2 * np.sin((time-ph2)*f2*400)\n",
    "#  series += 0.1* (np.random.rand(batch_size,n_steps,n_dim)-0.5)\n",
    "#  return series\n",
    "\n",
    "def generate_time_series(batch_size, n_steps):\n",
    "  f1,f2,ph1, ph2 = np.random.rand(4, batch_size,1)\n",
    "  time=np.linspace(0,1, n_steps)\n",
    "  series  = 0.5*np.sin((time-ph1)*f1*100)\n",
    "  series += 0.2 * np.sin((time-ph2)*f2*400)\n",
    "  series += 0.1* (np.random.rand(batch_size,n_steps)-0.5)\n",
    "  return series  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u2-Emu5w3nRz",
    "outputId": "7790e0e4-067d-43a7-dcf7-617d9636471f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 51)\n"
     ]
    }
   ],
   "source": [
    "n_sample = 5000\n",
    "n_steps = 50\n",
    "series = generate_time_series(n_sample, n_steps+1)\n",
    "Series=series.reshape((n_sample,n_steps+1,1))\n",
    "\n",
    "print(series.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cJb7glgjLV7o"
   },
   "source": [
    "# 2) Training step by step\n",
    "\n",
    "## 2.1) Layers as functions\n",
    "\n",
    "\n",
    "Applying a simpleRNN layer (3 units) to the inputs $X_0$ (1000 trajectories up to time $t=50$); the output should be a sequence. \n",
    "\n",
    "Applying a simpleRNN layer (1 unit) to $X_1$; the output being that of a Seq2seq model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Vc43ymtA373",
    "outputId": "c2f400ce-dc3e-4b08-a27e-12a83f308bed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 50, 1)\n",
      "[[[ 0.66225275]\n",
      "  [ 0.32064596]\n",
      "  [ 0.09007671]\n",
      "  ...\n",
      "  [ 0.49712428]\n",
      "  [ 0.3249121 ]\n",
      "  [ 0.40999295]]\n",
      "\n",
      " [[-0.17772733]\n",
      "  [ 0.13624392]\n",
      "  [ 0.60794034]\n",
      "  ...\n",
      "  [ 0.40943367]\n",
      "  [ 0.23435953]\n",
      "  [ 0.14617582]]\n",
      "\n",
      " [[ 0.53293663]\n",
      "  [ 0.22526757]\n",
      "  [-0.11386336]\n",
      "  ...\n",
      "  [ 0.37696882]\n",
      "  [ 0.10320845]\n",
      "  [-0.20891503]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.47934666]\n",
      "  [-0.50156481]\n",
      "  [-0.14949891]\n",
      "  ...\n",
      "  [-0.40245048]\n",
      "  [-0.71194123]\n",
      "  [-0.45659152]]\n",
      "\n",
      " [[-0.34125646]\n",
      "  [ 0.06521414]\n",
      "  [ 0.43507957]\n",
      "  ...\n",
      "  [-0.30939038]\n",
      "  [ 0.51261748]\n",
      "  [-0.15422766]]\n",
      "\n",
      " [[-0.62282205]\n",
      "  [-0.71653909]\n",
      "  [-0.73124321]\n",
      "  ...\n",
      "  [ 0.39364534]\n",
      "  [ 0.51208033]\n",
      "  [ 0.6190817 ]]]\n",
      "(5000, 50, 3)\n",
      "tf.Tensor(\n",
      "[[[ 0.33921528 -0.43598193  0.600492  ]\n",
      "  [-0.49241593  0.17347012  0.33224392]\n",
      "  [ 0.35152832  0.37959152 -0.16224378]\n",
      "  ...\n",
      "  [-0.06673425 -0.17252155  0.23508053]\n",
      "  [ 0.0123141  -0.02790023  0.18648027]\n",
      "  [ 0.1324764  -0.12013917  0.40418127]]\n",
      "\n",
      " [[-0.09450613  0.1247441  -0.1841015 ]\n",
      "  [ 0.27119124 -0.2196153   0.14063688]\n",
      "  [-0.0432911  -0.38250136  0.612587  ]\n",
      "  ...\n",
      "  [-0.0255209  -0.06065648  0.19894141]\n",
      "  [ 0.03384335  0.01645504  0.19265907]\n",
      "  [ 0.0108594   0.07586788  0.19465356]]\n",
      "\n",
      " [[ 0.27682117 -0.359245    0.50680226]\n",
      "  [-0.4359313   0.18184075  0.23751967]\n",
      "  [ 0.2545207   0.4157953  -0.3203721 ]\n",
      "  ...\n",
      "  [-0.10857751  0.01832194  0.4898605 ]\n",
      "  [-0.01751697  0.3978624   0.05461692]\n",
      "  [ 0.17619403  0.28097108  0.02153735]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.25022656  0.3258764  -0.46389663]\n",
      "  [ 0.25993556  0.03872203 -0.4858113 ]\n",
      "  [-0.05578797 -0.38519272  0.05007078]\n",
      "  ...\n",
      "  [-0.13280207  0.02833904 -0.5748271 ]\n",
      "  [-0.10265835 -0.00845513 -0.6925588 ]\n",
      "  [ 0.0241111  -0.30515417 -0.5297684 ]]\n",
      "\n",
      " [[-0.1800221   0.2362294  -0.3430741 ]\n",
      "  [ 0.39930892 -0.27403864  0.0653977 ]\n",
      "  [-0.22498557 -0.37382823  0.5324963 ]\n",
      "  ...\n",
      "  [-0.19532883 -0.1369628  -0.0974332 ]\n",
      "  [ 0.3072121  -0.4137472   0.28732747]\n",
      "  [-0.5788118   0.2207795  -0.17319646]]\n",
      "\n",
      " [[-0.3204743   0.4131787  -0.5734179 ]\n",
      "  [ 0.28368965  0.12015598 -0.64053154]\n",
      "  [-0.26555485 -0.12985821 -0.4585604 ]\n",
      "  ...\n",
      "  [-0.00838887 -0.2313105   0.1499898 ]\n",
      "  [ 0.05988012 -0.2603934   0.37085682]\n",
      "  [-0.01305643 -0.1523365   0.4963192 ]]], shape=(5000, 50, 3), dtype=float32)\n",
      "(5000, 50, 1)\n",
      "tf.Tensor(\n",
      "[[[-0.6699759 ]\n",
      "  [ 0.687267  ]\n",
      "  [-0.4758219 ]\n",
      "  ...\n",
      "  [-0.08079169]\n",
      "  [-0.05200417]\n",
      "  [-0.31792372]]\n",
      "\n",
      " [[ 0.23339964]\n",
      "  [-0.5362225 ]\n",
      "  [-0.05210468]\n",
      "  ...\n",
      "  [-0.10542271]\n",
      "  [-0.01225107]\n",
      "  [-0.05518528]]\n",
      "\n",
      " [[-0.5873408 ]\n",
      "  [ 0.65952444]\n",
      "  [-0.31400844]\n",
      "  ...\n",
      "  [ 0.23456416]\n",
      "  [ 0.00856323]\n",
      "  [ 0.07740741]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.546233  ]\n",
      "  [-0.3545534 ]\n",
      "  [ 0.09608465]\n",
      "  ...\n",
      "  [ 0.23522069]\n",
      "  [ 0.2089293 ]\n",
      "  [-0.11779389]]\n",
      "\n",
      " [[ 0.41992804]\n",
      "  [-0.68740356]\n",
      "  [ 0.23846963]\n",
      "  ...\n",
      "  [ 0.2326339 ]\n",
      "  [-0.6809944 ]\n",
      "  [ 0.8401694 ]]\n",
      "\n",
      " [[ 0.64710414]\n",
      "  [-0.32706416]\n",
      "  [ 0.56501573]\n",
      "  ...\n",
      "  [-0.33264908]\n",
      "  [-0.08617079]\n",
      "  [-0.28799263]]], shape=(5000, 50, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "X0=Series[:,:n_steps,:]\n",
    "print(X0.shape)\n",
    "print(X0)\n",
    "X1=tf.keras.layers.SimpleRNN(3, return_sequences=True,input_shape=[None,1])(X0)\n",
    "print(X1.shape)\n",
    "print(X1)\n",
    "X2=tf.keras.layers.SimpleRNN(1,return_sequences=True)(X1)\n",
    "print(X2.shape)\n",
    "print(X2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RBYgy4b2L6y7"
   },
   "source": [
    "## 2.2) Accessing the parameters\n",
    "\n",
    "\n",
    "Building an RNN $\\texttt{model}$ with two simpleRNN layers (3 and 1 units respectively) and only one output $y(50) \\approx x(51)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hiz7fST5KucX",
    "outputId": "33ba299b-b6d8-4ddf-e636-7b0d0276caa8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINABLE WEIGHTS [<tf.Variable 'simple_rnn_2/simple_rnn_cell_2/kernel:0' shape=(1, 3) dtype=float32, numpy=array([[-0.23641968,  0.14918315, -0.769784  ]], dtype=float32)>, <tf.Variable 'simple_rnn_2/simple_rnn_cell_2/recurrent_kernel:0' shape=(3, 3) dtype=float32, numpy=\n",
      "array([[-0.21063721, -0.77099264, -0.6010011 ],\n",
      "       [ 0.47261637, -0.61848545,  0.62778133],\n",
      "       [-0.85572535, -0.15180884,  0.49465972]], dtype=float32)>, <tf.Variable 'simple_rnn_2/simple_rnn_cell_2/bias:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>, <tf.Variable 'simple_rnn_3/simple_rnn_cell_3/kernel:0' shape=(3, 1) dtype=float32, numpy=\n",
      "array([[-0.53541654],\n",
      "       [ 0.07216978],\n",
      "       [ 0.5560576 ]], dtype=float32)>, <tf.Variable 'simple_rnn_3/simple_rnn_cell_3/recurrent_kernel:0' shape=(1, 1) dtype=float32, numpy=array([[1.]], dtype=float32)>, <tf.Variable 'simple_rnn_3/simple_rnn_cell_3/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "#log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "#tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "model=tf.keras.models.Sequential([\n",
    "    tf.keras.layers.SimpleRNN(3, return_sequences=True,input_shape=[None,1]),\n",
    "    tf.keras.layers.SimpleRNN(1)\n",
    "])\n",
    "\n",
    "#print('VARIABLES',model.variables)\n",
    "#print('TRAINABLE VARIABLES',model.trainable_variables)\n",
    "\n",
    "print('TRAINABLE WEIGHTS',model.trainable_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A1JEq1TrOR3i"
   },
   "source": [
    "## 2.3) Gradient and training\n",
    "\n",
    "\n",
    "\n",
    "Using $\\texttt{GradientTape}$, computing the derivatives of $\\displaystyle{\\frac{1}{1000} \\sum_{k=1}^{1000} \\left\\| \\hat{y}^{k}_2 (50) - x^k(51) \\right\\|^2}$ with respect to all the trainable parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7ykyHXo239zA",
    "outputId": "5649be1a-b8a8-467e-f3c9-e4320daabd3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_value tf.Tensor(0.4792969226837158, shape=(), dtype=float64)\n",
      "grad length 6\n",
      "gradient [<tf.Tensor: shape=(1, 3), dtype=float32, numpy=array([[ 0.07866429, -0.18679382,  0.11946323]], dtype=float32)>, <tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
      "array([[-0.09564289, -0.01420624, -0.06465584],\n",
      "       [-0.00377125,  0.0268035 ,  0.01120147],\n",
      "       [-0.10509069,  0.02422908, -0.07476117]], dtype=float32)>, <tf.Tensor: shape=(3,), dtype=float32, numpy=array([ 0.07012494, -0.18416154, -0.02856793], dtype=float32)>, <tf.Tensor: shape=(3, 1), dtype=float32, numpy=\n",
      "array([[-0.24019219],\n",
      "       [ 0.09486873],\n",
      "       [-0.2084916 ]], dtype=float32)>, <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.0600991]], dtype=float32)>, <tf.Tensor: shape=(1,), dtype=float32, numpy=array([-0.05794057], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "  X2=model(X0,training=True)\n",
    "  loss_value = loss_fn(X2, Series[:,-1,:])\n",
    "  print('loss_value',loss_value)\n",
    "  grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "  print('grad length', len(grads))\n",
    "  print('gradient',grads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8wiu6CK_OY_j"
   },
   "source": [
    "## 2.4) Training loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0m2PGLFpvoEo"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4sUmTKGSW42W",
    "outputId": "6f4f925e-ce6c-42b3-bdde-a06b12ab61ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_value tf.Tensor(0.4792969226837158, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.47718095779418945, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.4743861258029938, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.4711986780166626, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.46776890754699707, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.4641799330711365, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.460477352142334, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.45669320225715637, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.4528559446334839, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.44899141788482666, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.44512221217155457, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.44126787781715393, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.4374452233314514, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.4336685538291931, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.429950088262558, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.42629972100257874, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.422725111246109, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.419231653213501, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.4158225655555725, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.41249892115592957, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.40926000475883484, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.40610289573669434, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.40302348136901855, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.4000166952610016, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.39707741141319275, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.3942011892795563, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.39138466119766235, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.3886256515979767, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.38592323660850525, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.38327714800834656, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.380687415599823, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.37815365195274353, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.37567487359046936, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.3732488751411438, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.37087252736091614, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.3685418367385864, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.36625218391418457, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.36399906873703003, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.36177822947502136, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.3595861792564392, shape=(), dtype=float64)\n",
      "duration of the loop 5.859090566635132\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_epoch=2\n",
    "\n",
    "start=time.time()\n",
    "for epoch in range(n_epoch):\n",
    "  with tf.GradientTape() as tape:\n",
    "    X2=model(X0,training=True)\n",
    "    loss_value = loss_fn(X2, Series[:,-1,:])\n",
    "    print('loss_value',loss_value)\n",
    "    grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "    #print('grad length', len(grads))\n",
    "    #print('grads W_0 ',grads[0])\n",
    "    #print('grads WR_0',grads[1])\n",
    "    #print('old weights',model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "    #print('update weights',model.trainable_weights[3])\n",
    "    #print('diff',model.trainable_weights[0]-old_weights[0])\n",
    "    #print('diff',model.trainable_weights[1]-old_weights[1])\n",
    "    #print('diff',model.trainable_weights[2]-old_weights[2])\n",
    "\n",
    "print('duration of the loop',time.time()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0g5AQJ_bqAfb"
   },
   "source": [
    "## 2.5) Graph execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tVt1hZc4qCY6",
    "outputId": "4969b390-f95b-4625-979c-3905fa4027e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "Num CPUs Available:  1\n",
      "Num TPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(\"Num CPUs Available: \", len(tf.config.list_physical_devices('CPU')))\n",
    "print(\"Num TPUs Available: \", len(tf.config.list_physical_devices('TPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NLpx3arC60Oz"
   },
   "outputs": [],
   "source": [
    "## graph execution \n",
    "\n",
    "@tf.function \n",
    "def train_tffunct(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        X2=model(x,training=True)\n",
    "        loss_value = loss_fn(X2, y)\n",
    "    grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "    return loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tzUmQacZ7V5d",
    "outputId": "2769e6b0-eb75-4ef4-e40d-d558f3650f40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_value tf.Tensor(0.35742056369781494, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.3552796542644501, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.3531627058982849, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.3510694205760956, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.34899967908859253, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.3469533622264862, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.3449302613735199, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.34292978048324585, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.34095126390457153, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.3389938473701477, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.33705660700798035, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.3351387083530426, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.33323934674263, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.3313578963279724, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.3294937014579773, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.3276463747024536, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.325815349817276, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.32400038838386536, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.3222010135650635, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.3204168975353241, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.31864750385284424, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.3168925642967224, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.31515148282051086, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.3134240210056305, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.31170982122421265, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.3100084364414215, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.3083198368549347, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.3066437840461731, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.3049803078174591, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.30332934856414795, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.30169111490249634, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.3000657260417938, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.2984534502029419, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.29685458540916443, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.29526928067207336, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.2936975955963135, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.29213911294937134, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.290593683719635, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.2890602648258209, shape=(), dtype=float64)\n",
      "loss_value tf.Tensor(0.28753605484962463, shape=(), dtype=float64)\n",
      "duration of the loop 3.8100457191467285\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "  with tf.GradientTape() as tape:\n",
    "    loss_value = train_tffunct(X0,Series[:,-1,:])\n",
    "    print('loss_value',loss_value)\n",
    "\n",
    "\n",
    "print('duration of the loop',time.time()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_C5cYXpxu2ET"
   },
   "source": [
    "## 2.6) Graph Optimization\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WcpOHtf1vJFr",
    "outputId": "0a34743a-7d3f-44ae-98a4-0bfc7b9612d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'constant_folding': True, 'disable_model_pruning': False, 'disable_meta_optimizer': False}\n",
      "{'constant_folding': True, 'disable_model_pruning': False, 'disable_meta_optimizer': False}\n"
     ]
    }
   ],
   "source": [
    "opts = tf.config.optimizer.get_experimental_options()\n",
    "print(opts)\n",
    "tf.config.optimizer.set_experimental_options({'constant_folding': True})\n",
    "tf.config.optimizer.set_experimental_options({'arithmetic_optimizer': True})\n",
    "tf.config.optimizer.set_experimental_options({'shape_optimizer': True})\n",
    "opts = tf.config.optimizer.get_experimental_options()\n",
    "print(opts)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
